groups:
  - name: honua_availability
    interval: 30s
    rules:
      - alert: HonuaHighErrorRate
        expr: |
          (
            sum(rate(honua_api_errors_total{job="honua"}[5m]))
            /
            sum(rate(honua_api_requests_total{job="honua"}[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          service: honua
          category: availability
        annotations:
          summary: "High API error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%). Total errors in last 5m: {{ with query \"sum(increase(honua_api_errors_total{job='honua'}[5m]))\" }}{{ . | first | value | humanize }}{{ end }}"
          runbook_url: "https://docs.honua.io/runbooks/high-error-rate"

      - alert: HonuaServiceDown
        expr: up{job="honua"} == 0
        for: 1m
        labels:
          severity: critical
          service: honua
          category: availability
        annotations:
          summary: "Honua service is down"
          description: "The Honua server at {{ $labels.instance }} has been down for more than 1 minute."
          runbook_url: "https://docs.honua.io/runbooks/service-down"

      - alert: HonuaHighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(honua_api_request_duration_ms_bucket{job="honua"}[5m])) by (le)
          ) > 2000
        for: 10m
        labels:
          severity: warning
          service: honua
          category: performance
        annotations:
          summary: "High API latency detected"
          description: "P95 latency is {{ $value | humanize }}ms (threshold: 2000ms)"
          runbook_url: "https://docs.honua.io/runbooks/high-latency"

      - alert: HonuaCriticalLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(honua_api_request_duration_ms_bucket{job="honua"}[5m])) by (le)
          ) > 5000
        for: 5m
        labels:
          severity: critical
          service: honua
          category: performance
        annotations:
          summary: "Critical API latency detected"
          description: "P95 latency is {{ $value | humanize }}ms (threshold: 5000ms). Users experiencing severe degradation."
          runbook_url: "https://docs.honua.io/runbooks/critical-latency"

  - name: honua_resources
    interval: 30s
    rules:
      - alert: HonuaHighMemoryUsage
        expr: |
          (process_resident_memory_bytes{job="honua"} / (1024 * 1024 * 1024)) > 8
        for: 5m
        labels:
          severity: warning
          service: honua
          category: resources
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value | humanize }}GB (threshold: 8GB)"
          runbook_url: "https://docs.honua.io/runbooks/high-memory"

      - alert: HonuaCriticalMemoryUsage
        expr: |
          (process_resident_memory_bytes{job="honua"} / (1024 * 1024 * 1024)) > 12
        for: 2m
        labels:
          severity: critical
          service: honua
          category: resources
        annotations:
          summary: "Critical memory usage detected"
          description: "Memory usage is {{ $value | humanize }}GB (threshold: 12GB). Risk of OOM."
          runbook_url: "https://docs.honua.io/runbooks/critical-memory"

      - alert: HonuaHighCPUUsage
        expr: |
          rate(process_cpu_seconds_total{job="honua"}[5m]) > 0.8
        for: 10m
        labels:
          severity: warning
          service: honua
          category: resources
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value | humanizePercentage }} (threshold: 80%)"
          runbook_url: "https://docs.honua.io/runbooks/high-cpu"

      - alert: HonuaThreadPoolExhaustion
        expr: |
          dotnet_threadpool_num_threads{job="honua"} > 500
        for: 5m
        labels:
          severity: warning
          service: honua
          category: resources
        annotations:
          summary: "ThreadPool exhaustion detected"
          description: "ThreadPool has {{ $value }} threads (threshold: 500). May indicate thread starvation."
          runbook_url: "https://docs.honua.io/runbooks/threadpool-exhaustion"

  - name: honua_raster_cache
    interval: 30s
    rules:
      - alert: HonuaLowCacheHitRate
        expr: |
          (
            sum(rate(honua_raster_cache_hits_total{job="honua"}[10m]))
            /
            (
              sum(rate(honua_raster_cache_hits_total{job="honua"}[10m]))
              +
              sum(rate(honua_raster_cache_misses_total{job="honua"}[10m]))
            )
          ) < 0.7
        for: 15m
        labels:
          severity: warning
          service: honua
          category: cache
        annotations:
          summary: "Low raster cache hit rate"
          description: "Cache hit rate is {{ $value | humanizePercentage }} (threshold: 70%). Consider increasing cache size or TTL."
          runbook_url: "https://docs.honua.io/runbooks/low-cache-hit-rate"

      - alert: HonuaHighRasterRenderLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(honua_raster_render_latency_ms_bucket{job="honua",source="request"}[5m])) by (le)
          ) > 1000
        for: 10m
        labels:
          severity: warning
          service: honua
          category: performance
        annotations:
          summary: "High raster render latency"
          description: "P95 render latency is {{ $value | humanize }}ms (threshold: 1000ms)"
          runbook_url: "https://docs.honua.io/runbooks/high-render-latency"

      - alert: HonuaPreseedJobsFailingFrequently
        expr: |
          sum(rate(honua_raster_preseed_jobs_failed_total{job="honua"}[1h])) > 0.1
        for: 5m
        labels:
          severity: warning
          service: honua
          category: cache
        annotations:
          summary: "Raster preseed jobs failing frequently"
          description: "Preseed job failure rate is {{ $value | humanize }} per second over the last hour"
          runbook_url: "https://docs.honua.io/runbooks/preseed-failures"

  - name: honua_errors
    interval: 30s
    rules:
      - alert: HonuaDatabaseErrors
        expr: |
          sum(rate(honua_api_errors_total{job="honua",error_category="database"}[5m])) > 0.5
        for: 5m
        labels:
          severity: critical
          service: honua
          category: database
        annotations:
          summary: "High rate of database errors"
          description: "Database error rate is {{ $value | humanize }} per second. Check database connectivity and health."
          runbook_url: "https://docs.honua.io/runbooks/database-errors"

      - alert: HonuaStorageErrors
        expr: |
          sum(rate(honua_api_errors_total{job="honua",error_category="storage"}[5m])) > 0.5
        for: 5m
        labels:
          severity: critical
          service: honua
          category: storage
        annotations:
          summary: "High rate of storage errors"
          description: "Storage error rate is {{ $value | humanize }} per second. Check disk space and I/O health."
          runbook_url: "https://docs.honua.io/runbooks/storage-errors"

      - alert: HonuaSecurityErrors
        expr: |
          sum(rate(honua_api_errors_total{job="honua",error_category="security"}[5m])) > 1
        for: 2m
        labels:
          severity: critical
          service: honua
          category: security
        annotations:
          summary: "High rate of security errors"
          description: "Security error rate is {{ $value | humanize }} per second. Possible security breach or misconfiguration."
          runbook_url: "https://docs.honua.io/runbooks/security-errors"

      - alert: HonuaOutOfMemoryErrors
        expr: |
          sum(increase(honua_api_errors_total{job="honua",error_type="out_of_memory"}[5m])) > 0
        for: 1m
        labels:
          severity: critical
          service: honua
          category: resources
        annotations:
          summary: "Out of memory errors detected"
          description: "{{ $value }} OOM errors in the last 5 minutes. Immediate action required."
          runbook_url: "https://docs.honua.io/runbooks/oom-errors"

  - name: honua_business_metrics
    interval: 1m
    rules:
      - alert: HonuaLowRequestVolume
        expr: |
          sum(rate(honua_api_requests_total{job="honua"}[10m])) < 1
        for: 30m
        labels:
          severity: warning
          service: honua
          category: business
        annotations:
          summary: "Unusually low request volume"
          description: "Request rate is {{ $value | humanize }} req/s (threshold: < 1 req/s). May indicate connectivity issues or service discovery problems."
          runbook_url: "https://docs.honua.io/runbooks/low-traffic"

      - alert: HonuaNoTrafficByProtocol
        expr: |
          absent_over_time(honua_api_requests_total{job="honua",api_protocol=~"wfs|wms|ogc-api-features"}[1h])
        for: 15m
        labels:
          severity: info
          service: honua
          category: business
        annotations:
          summary: "No traffic for protocol {{ $labels.api_protocol }}"
          description: "Protocol {{ $labels.api_protocol }} has received no requests in the last hour."
          runbook_url: "https://docs.honua.io/runbooks/protocol-no-traffic"

  - name: honua_slo
    interval: 1m
    rules:
      - alert: HonuaAvailabilitySLOBreach
        expr: |
          (
            1 - (
              sum(rate(honua_api_errors_total{job="honua"}[30d]))
              /
              sum(rate(honua_api_requests_total{job="honua"}[30d]))
            )
          ) < 0.999
        for: 5m
        labels:
          severity: critical
          service: honua
          category: slo
        annotations:
          summary: "Availability SLO breach (30d)"
          description: "30-day availability is {{ $value | humanizePercentage }} (SLO: 99.9%). Error budget exhausted."
          runbook_url: "https://docs.honua.io/runbooks/slo-breach"

      - alert: HonuaLatencySLOBreach
        expr: |
          (
            histogram_quantile(0.95,
              sum(rate(honua_api_request_duration_ms_bucket{job="honua"}[30d])) by (le)
            ) > 2000
          )
        for: 1h
        labels:
          severity: warning
          service: honua
          category: slo
        annotations:
          summary: "Latency SLO breach (30d)"
          description: "30-day P95 latency is {{ $value | humanize }}ms (SLO: < 2000ms)"
          runbook_url: "https://docs.honua.io/runbooks/latency-slo-breach"
